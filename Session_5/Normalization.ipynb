{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abby263/TSAI_EVA_8/blob/main/Session_5/Normalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR,OneCycleLR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "dropout_value = 0.1\n",
        "num_groups = 2\n",
        "\n",
        "# Layer Normalization\n",
        "# Source : https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, norm_type='batch'):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.norm_type = norm_type\n",
        "\n",
        "        self.conv_block1 = self.conv_block(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False, output_size=26)  # (28, 28, 1) --> (26, 26, 8)\n",
        "        self.conv_block2 = self.conv_block(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False, output_size=24) # (26, 26, 8) --> (24, 24, 16)\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.transitionblock = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)) # (24, 24, 16) --> (24, 24, 10)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # (24, 24, 10) --> (12, 12, 10)\n",
        "\n",
        "        self.conv_block3 = self.conv_block(in_channels=10, out_channels=8, kernel_size=(3, 3), padding=0, bias=False, output_size=10) # (12, 12, 10) --> (10, 10, 8)\n",
        "        self.conv_block4 = self.conv_block(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=0, bias=False, output_size=8) # (10, 10, 8) --> (8, 8, 8)\n",
        "        self.conv_block5 = self.conv_block(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=0, bias=False, output_size=6) # (8, 8, 8) --> (6, 6, 8)\n",
        "        self.conv_block6 = self.conv_block(in_channels=8, out_channels=8, kernel_size=(3, 3), padding=1, bias=False, output_size=6) # (6, 6, 8) --> (6, 6, 8)\n",
        "        \n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=6)) #  (6, 6, 8) --> (1, 1, 8)\n",
        "\n",
        "        self.convblockoutput = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=8, out_channels=10, kernel_size=(1, 1), padding=0, bias=False)) # (1, 1, 8) --> (1, 1, 10) \n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_value)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels, kernel_size, padding, bias, output_size=None):\n",
        "      \n",
        "      if self.norm_type == 'batch':\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) \n",
        "      elif self.norm_type == 'layer':\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm([out_channels, output_size, output_size]),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )\n",
        "      elif self.norm_type == 'group':\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.GroupNorm(num_groups, out_channels),\n",
        "            nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block1(x)\n",
        "        x = self.conv_block2(x)\n",
        "        x = self.transitionblock(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv_block3(x)\n",
        "        x = self.conv_block4(x)\n",
        "        x = self.conv_block5(x)\n",
        "        x = self.conv_block6(x)\n",
        "       \n",
        "        x = self.gap(x)        \n",
        "        x = self.convblockoutput(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "        "
      ],
      "metadata": {
        "id": "QR9GDNElNr6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net(norm_type='group').to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrmmlDoTUrnd",
        "outputId": "75e7f1dd-8868-4c44-e1c5-a3f918594cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "         GroupNorm-3            [-1, 8, 26, 26]              16\n",
            "           Dropout-4            [-1, 8, 26, 26]               0\n",
            "            Conv2d-5           [-1, 16, 24, 24]           1,152\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "         GroupNorm-7           [-1, 16, 24, 24]              32\n",
            "           Dropout-8           [-1, 16, 24, 24]               0\n",
            "            Conv2d-9           [-1, 10, 24, 24]             160\n",
            "        MaxPool2d-10           [-1, 10, 12, 12]               0\n",
            "           Conv2d-11            [-1, 8, 10, 10]             720\n",
            "             ReLU-12            [-1, 8, 10, 10]               0\n",
            "        GroupNorm-13            [-1, 8, 10, 10]              16\n",
            "          Dropout-14            [-1, 8, 10, 10]               0\n",
            "           Conv2d-15              [-1, 8, 8, 8]             576\n",
            "             ReLU-16              [-1, 8, 8, 8]               0\n",
            "        GroupNorm-17              [-1, 8, 8, 8]              16\n",
            "          Dropout-18              [-1, 8, 8, 8]               0\n",
            "           Conv2d-19              [-1, 8, 6, 6]             576\n",
            "             ReLU-20              [-1, 8, 6, 6]               0\n",
            "        GroupNorm-21              [-1, 8, 6, 6]              16\n",
            "          Dropout-22              [-1, 8, 6, 6]               0\n",
            "           Conv2d-23              [-1, 8, 6, 6]             576\n",
            "             ReLU-24              [-1, 8, 6, 6]               0\n",
            "        GroupNorm-25              [-1, 8, 6, 6]              16\n",
            "          Dropout-26              [-1, 8, 6, 6]               0\n",
            "        AvgPool2d-27              [-1, 8, 1, 1]               0\n",
            "           Conv2d-28             [-1, 10, 1, 1]              80\n",
            "================================================================\n",
            "Total params: 4,024\n",
            "Trainable params: 4,024\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.56\n",
            "Params size (MB): 0.02\n",
            "Estimated Total Size (MB): 0.58\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "lambda_l1 = 0.01\n",
        "lambda_orth = 0.01 \n",
        "\n",
        "def l1_regularizer(model, lambda_l1=0.01):\n",
        "    lossl1 = 0\n",
        "    for model_param_name, model_param_value in model.named_parameters():\n",
        "            if model_param_name.endswith('weight'):\n",
        "                lossl1 += lambda_l1 * model_param_value.abs().sum()\n",
        "    return lossl1\n",
        "\n",
        "def orth_regularizer(model, lambda_orth=0.01):\n",
        "    lossorth = 0\n",
        "    for model_param_name, model_param_value in model.named_parameters():\n",
        "            if model_param_name.endswith('weight'):\n",
        "                param_flat = model_param_value.view(model_param_value.shape[0], -1)\n",
        "                sym = torch.mm(param_flat, torch.t(param_flat))\n",
        "                sym -= torch.eye(param_flat.shape[0])\n",
        "                lossorth += lambda_orth * sym.sum()\n",
        "    return lossorth\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "def train_l1_loss(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target) + l1_regularizer(model, lambda_l1=lambda_l1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "for epoch in range(1, 20):\n",
        "  print('Epoch :', epoch)\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test(model, device, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f-4U6LlWVnT7",
        "outputId": "e6206781-edac-4343-f0ab-ffff754e9451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.2858213484287262 batch_id=468: 100%|██████████| 469/469 [00:53<00:00,  8.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1378, Accuracy: 9641/10000 (96.41%)\n",
            "\n",
            "Epoch : 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.10322775691747665 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0861, Accuracy: 9754/10000 (97.54%)\n",
            "\n",
            "Epoch : 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.06175832077860832 batch_id=468: 100%|██████████| 469/469 [00:51<00:00,  9.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0804, Accuracy: 9749/10000 (97.49%)\n",
            "\n",
            "Epoch : 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.025359751656651497 batch_id=468: 100%|██████████| 469/469 [00:58<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0685, Accuracy: 9783/10000 (97.83%)\n",
            "\n",
            "Epoch : 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.12874558568000793 batch_id=468: 100%|██████████| 469/469 [00:50<00:00,  9.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0715, Accuracy: 9780/10000 (97.80%)\n",
            "\n",
            "Epoch : 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.15431112051010132 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0493, Accuracy: 9843/10000 (98.43%)\n",
            "\n",
            "Epoch : 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08965524286031723 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0480, Accuracy: 9846/10000 (98.46%)\n",
            "\n",
            "Epoch : 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.04730834439396858 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0462, Accuracy: 9857/10000 (98.57%)\n",
            "\n",
            "Epoch : 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08937542885541916 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0401, Accuracy: 9879/10000 (98.79%)\n",
            "\n",
            "Epoch : 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05042794719338417 batch_id=468: 100%|██████████| 469/469 [00:48<00:00,  9.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0425, Accuracy: 9876/10000 (98.76%)\n",
            "\n",
            "Epoch : 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.055991753935813904 batch_id=468: 100%|██████████| 469/469 [00:49<00:00,  9.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0397, Accuracy: 9878/10000 (98.78%)\n",
            "\n",
            "Epoch : 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.11887814849615097 batch_id=372:  80%|███████▉  | 373/469 [00:44<00:11,  8.37it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4e72ee2dcd5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2a966a523430>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34mf'loss={loss.item()} batch_id={batch_idx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def wrong_predictions(test_loader,model,device):\n",
        "  wrong_images=[]\n",
        "  wrong_label=[]\n",
        "  correct_label=[]\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)        \n",
        "      pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "      wrong_pred = (pred.eq(target.view_as(pred)) == False)\n",
        "      wrong_images.append(data[wrong_pred])\n",
        "      wrong_label.append(pred[wrong_pred])\n",
        "      correct_label.append(target.view_as(pred)[wrong_pred])  \n",
        "      \n",
        "      wrong_predictions = list(zip(torch.cat(wrong_images),torch.cat(wrong_label),torch.cat(correct_label)))    \n",
        "    print(f'Total wrong predictions are {len(wrong_predictions)}')\n",
        "      \n",
        "      \n",
        "    fig = plt.figure(figsize=(8,10))\n",
        "    fig.tight_layout()\n",
        "    for i, (img, pred, correct) in enumerate(wrong_predictions[:10]):\n",
        "          img, pred, target = img.cpu().numpy(), pred.cpu(), correct.cpu()\n",
        "          ax = fig.add_subplot(5, 2, i+1)\n",
        "          ax.axis('off')\n",
        "          ax.set_title(f'\\nactual {target.item()}\\npredicted {pred.item()}',fontsize=10)  \n",
        "          ax.imshow(img.squeeze(), cmap='gray_r')  \n",
        "          \n",
        "    plt.show()\n",
        "      \n",
        "  return "
      ],
      "metadata": {
        "id": "K6MbCvuxk09D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wrong_predictions(test_loader,model,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "YcStzG6KhQBN",
        "outputId": "d05dc54a-1cfb-41fd-8d23-fd63d2179560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total wrong predictions are 189\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x720 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z0TJAbiUhXqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}