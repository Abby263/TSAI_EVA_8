{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abby263/TSAI_EVA_8/blob/main/Session_2.5/EVA_Session_2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZUA6dENgx-m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PAwcK54g2IN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# torchvision.datasets.MNIST outputs a set of PIL images\n",
        "# Load and transform data\n",
        "MNIST_train = torchvision.datasets.MNIST('/tmp', train=True, download=True, transform=transform)\n",
        "MNIST_trainset, MNIST_valset = torch.utils.data.random_split(MNIST_train, [55000, 5000])\n",
        "MNIST_testset = torchvision.datasets.MNIST('/tmp', train=False, download=True, transform=transform)\n",
        "\n",
        "class RMNISTDataset(Dataset):\n",
        "  def __init__(self, mnist_data):\n",
        "    self.mnist_dataset = mnist_data\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.mnist_dataset)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image, label = self.mnist_dataset[idx]\n",
        "    random_number = torch.randint(0, 10, size=(1,)).long()\n",
        "    rand_num_onehot = F.one_hot(random_number, num_classes = 10).view(random_number.size(0), -1)\n",
        "    return image, label, random_number, rand_num_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "T95MCAqZxGRZ",
        "outputId": "236b7dc3-adaa-4d52-e374-0d86f54dd9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of images in train dataset - 55000\n",
            "The number of images in val dataset - 5000\n",
            "The number of images in test dataset - 10000\n",
            "Feature batch shape: torch.Size([8, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([8])\n",
            "labels: tensor([2, 3, 7, 3, 2, 2, 3, 4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Create an instance of the MNISTDataset class\n",
        "train_dataset = RMNISTDataset(MNIST_trainset)\n",
        "val_dataset = RMNISTDataset(MNIST_valset)\n",
        "test_dataset = RMNISTDataset(MNIST_testset)\n",
        "\n",
        "print(f'The number of images in train dataset - {len(train_dataset)}')\n",
        "print(f'The number of images in val dataset - {len(val_dataset)}')\n",
        "print(f'The number of images in test dataset - {len(test_dataset)}')\n",
        "\n",
        "batch_size = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "batch = next(iter(train_loader))\n",
        "images, labels, rand_num, rand_num_onehot = batch \n",
        "\n",
        "print(f\"Feature batch shape: {images.size()}\")\n",
        "print(f\"Labels batch shape: {labels.size()}\")\n",
        "\n",
        "grid = torchvision.utils.make_grid(images, nrow=10)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "print('labels:', labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVlg_K-CgOjE",
        "outputId": "fa89e613-0a7a-4cdb-ccc4-b72bd5834604"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (fc3): Linear(in_features=10, out_features=120, bias=True)\n",
              "  (fc4): Linear(in_features=120, out_features=60, bias=True)\n",
              "  (out1): Linear(in_features=60, out_features=10, bias=True)\n",
              "  (out2): Linear(in_features=60, out_features=19, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3) \n",
        "    self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "    self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "    self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3)\n",
        "    self.conv5 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "    self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3)\n",
        "    self.fc1 = nn.Linear(in_features=1024 * 7 * 7, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.fc3 = nn.Linear(in_features=10, out_features=120)\n",
        "    self.fc4 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out1 = nn.Linear(in_features=60, out_features=10)\n",
        "    self.out2 = nn.Linear(in_features=60, out_features=19)\n",
        "    self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "  def forward(self, t, r):\n",
        "    # input layer\n",
        "    x = t\n",
        "    # conv1 layer\n",
        "    x = F.relu(self.conv1(x)) # (28, 28, 1) --> (26, 26, 32) RF : 3x3\n",
        "    # conv2 layer\n",
        "    x = F.relu(self.conv2(x)) # (26, 26, 32) --> (24, 24, 64) RF : 5x5\n",
        "    # conv3 layer\n",
        "    x = F.relu(self.conv3(x)) # (24, 24, 64) --> (22, 22, 128) RF : 7x7\n",
        "    # conv4 layer\n",
        "    x = F.relu(self.conv4(x)) # (22, 22, 128) --> (20, 20, 256) RF : 9x9\n",
        "    # conv5 layer\n",
        "    x = F.relu(self.conv5(x)) # (20, 20, 256) --> (18, 18, 512) RF : 11x11\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2) # (18, 18, 512)  --> (9, 9, 512) RF : 22X22\n",
        "    # conv6 layer\n",
        "    x = F.relu(self.conv6(x)) # (9, 9, 512) --> (7, 7, 1024) RF : 24X24\n",
        "    # reshape\n",
        "    x = x.reshape(-1, 1024 * 7 * 7)\n",
        "    # fc1 layer\n",
        "    x = self.fc1(x)\n",
        "    # fc2 layer\n",
        "    x = self.fc2(x)\n",
        "    # output layer 1\n",
        "    x = self.out1(x)\n",
        "    # fc3 layer\n",
        "    sum_output = self.fc3(r.to(torch.float32))\n",
        "    # fc4 layer\n",
        "    sum_output = self.fc4(sum_output)\n",
        "    # output layer 2\n",
        "    sum_predict = self.out2(sum_output)\n",
        "    return F.log_softmax(x, dim=1), F.log_softmax(sum_predict, dim=1)\n",
        "\n",
        "network = Network()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "network.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9mq9tjmq9mB",
        "outputId": "a8f54002-0216-4cd4-8925-2ea38b5e98c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 12,326,465 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(network):,} trainable parameters')\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gokxixUgtS6"
      },
      "outputs": [],
      "source": [
        "def train(network, train_loader, optimizer, num_epochs, device):\n",
        "\n",
        "  network = network.train()\n",
        "  \n",
        "  total_loss_mnist = 0\n",
        "  total_loss_sum = 0\n",
        "\n",
        "  for batch in train_loader: # Get Batch\n",
        "      images, labels, rand_num, rand_num_onehot = batch \n",
        "      images, labels, rand_num, rand_num_onehot = images.to(device), labels.to(device), rand_num.to(device), rand_num_onehot.to(device)\n",
        "\n",
        "      preds, sum_preds = network(images, rand_num_onehot) # Pass Batch\n",
        "      preds, sum_preds = preds.to(device), sum_preds.to(device) \n",
        "\n",
        "      sum_preds = sum_preds.view(sum_preds.size(0), -1)\n",
        "      sum_labels = (labels.squeeze() + rand_num.squeeze())\n",
        "\n",
        "      loss_mnist = F.nll_loss(preds, labels) # Calculate Loss\n",
        "      loss_sum = F.nll_loss(sum_preds, sum_labels) # Calculate Loss\n",
        "\n",
        "      loss = (loss_mnist + loss_sum)/2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() # Calculate Gradients\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_mnist += loss_mnist.item()\n",
        "\n",
        "      total_loss_sum += loss_sum.item()\n",
        "\n",
        "  print(f'epoch: {epoch} , loss mnist : {total_loss_mnist}, loss sum : {total_loss_sum}')\n",
        "\n",
        "  return loss\n",
        "\n",
        "\n",
        "def test(network, test_loader, device, test_type='Val'):\n",
        "\n",
        "  network = network.eval()\n",
        "\n",
        "  total_correct_mnist = 0\n",
        "  total_correct_sum = 0\n",
        "  total_loss_mnist = 0\n",
        "  total_loss_sum = 0\n",
        "\n",
        "  # turn off gradients during the testing\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch in test_loader: # Get Batch\n",
        "        images, labels, rand_num, rand_num_onehot = batch \n",
        "        images, labels, rand_num, rand_num_onehot = images.to(device), labels.to(device), rand_num.to(device), rand_num_onehot.to(device)\n",
        "\n",
        "        preds, sum_preds = network(images, rand_num_onehot) # Pass Batch\n",
        "        preds, sum_preds = preds.to(device), sum_preds.to(device) \n",
        "\n",
        "        sum_preds = sum_preds.view(sum_preds.size(0), -1)\n",
        "        sum_labels = (labels.squeeze() + rand_num.squeeze())\n",
        "\n",
        "        loss_mnist = F.nll_loss(preds, labels) # Calculate Loss\n",
        "        loss_sum = F.nll_loss(sum_preds, sum_labels) # Calculate Loss\n",
        "\n",
        "        loss = (loss_mnist + loss_sum)/2\n",
        "\n",
        "        total_loss_mnist += loss_mnist.item()\n",
        "        total_correct_mnist += get_num_correct(preds, labels)\n",
        "\n",
        "        total_loss_sum += loss_sum.item()\n",
        "        total_correct_sum += get_num_correct(sum_preds, sum_labels)\n",
        "\n",
        "  print(f'{test_type} set: Average loss: {loss:.3f}, MNIST Accuracy:{100. * total_correct_mnist/len(test_loader.dataset)}, Sum_Accuracy:{100. * total_correct_sum/len(test_loader.dataset)}')\n",
        "    \n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zI_LfCJSi0td",
        "outputId": "082c878c-c5db-42a9-c2a9-8bd1f63a6064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 : \n",
            "epoch: 1 , loss mnist : 4836.4594547423185, loss sum : 0.0\n",
            "Val set: Average loss: 0.138, MNIST Accuracy:95.62, Sum_Accuracy:1.2\n",
            "\n",
            "Epoch 2 : \n",
            "epoch: 2 , loss mnist : 829.8254803930613, loss sum : 0.0\n",
            "Val set: Average loss: 0.106, MNIST Accuracy:96.96, Sum_Accuracy:1.18\n",
            "\n",
            "Epoch 3 : \n",
            "epoch: 3 , loss mnist : 559.0599792947141, loss sum : 0.0\n",
            "Val set: Average loss: 0.023, MNIST Accuracy:98.12, Sum_Accuracy:1.3\n",
            "\n",
            "Epoch 4 : \n",
            "epoch: 4 , loss mnist : 426.3578369369934, loss sum : 0.0\n",
            "Val set: Average loss: 0.018, MNIST Accuracy:98.16, Sum_Accuracy:1.14\n",
            "\n",
            "Epoch 5 : \n",
            "epoch: 5 , loss mnist : 343.4942731789979, loss sum : 0.0\n",
            "Val set: Average loss: 0.014, MNIST Accuracy:98.58, Sum_Accuracy:1.0\n",
            "\n",
            "Epoch 6 : \n",
            "epoch: 6 , loss mnist : 281.4830155648451, loss sum : 0.0\n",
            "Val set: Average loss: 0.001, MNIST Accuracy:98.84, Sum_Accuracy:1.12\n",
            "\n",
            "Epoch 7 : \n",
            "epoch: 7 , loss mnist : 240.01546333435635, loss sum : 0.0\n",
            "Val set: Average loss: 0.001, MNIST Accuracy:98.8, Sum_Accuracy:1.1\n",
            "\n",
            "Epoch 8 : \n",
            "epoch: 8 , loss mnist : 206.07607260052555, loss sum : 0.0\n",
            "Val set: Average loss: 0.001, MNIST Accuracy:98.82, Sum_Accuracy:1.0\n",
            "\n",
            "Epoch 9 : \n",
            "epoch: 9 , loss mnist : 176.6826218062921, loss sum : 0.0\n",
            "Val set: Average loss: 0.001, MNIST Accuracy:99.14, Sum_Accuracy:1.16\n",
            "\n",
            "Epoch 10 : \n",
            "epoch: 10 , loss mnist : 149.8762259758117, loss sum : 0.0\n",
            "Val set: Average loss: 0.000, MNIST Accuracy:99.1, Sum_Accuracy:1.06\n",
            "\n",
            "Epoch 11 : \n",
            "epoch: 11 , loss mnist : 129.74019905708167, loss sum : 0.0\n",
            "Val set: Average loss: 0.000, MNIST Accuracy:98.92, Sum_Accuracy:1.16\n",
            "\n",
            "Epoch 12 : \n",
            "epoch: 12 , loss mnist : 112.37398477480549, loss sum : 0.0\n",
            "Val set: Average loss: 0.000, MNIST Accuracy:98.96, Sum_Accuracy:0.96\n",
            "\n",
            "Epoch 13 : \n",
            "epoch: 13 , loss mnist : 97.15604779740968, loss sum : 0.0\n",
            "Val set: Average loss: 0.000, MNIST Accuracy:98.84, Sum_Accuracy:0.98\n",
            "\n",
            "Epoch 14 : \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-07555f8b4015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch {} : '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# test the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-480c506612b5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, train_loader, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Calculate Gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Update Weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# move the model to the specified device\n",
        "network = network.to(device)\n",
        "\n",
        "# use Stochastic Gradient Descent as the optimizer\n",
        "optimizer = optim.SGD(network.parameters(), lr=0.001, momentum=0.7)\n",
        "\n",
        "# set the number of epochs to train for\n",
        "num_epoch = 25\n",
        "\n",
        "train_loss_values = []\n",
        "valid_loss_values = []\n",
        "\n",
        "# run it for epoch number of times\n",
        "for epoch in range(1, num_epoch+1):\n",
        "    print('\\nEpoch {} : '.format(epoch))\n",
        "    # train the model\n",
        "    train_loss = train(network, train_loader, optimizer, epoch, device)\n",
        "    valid_loss = test(network, val_loader, device)\n",
        "    # test the model\n",
        "    train_loss_values.append(train_loss)\n",
        "    valid_loss_values.append(valid_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1G7keKAPyrlb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMegB1mH29lppTN4HU8v/Tq",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}